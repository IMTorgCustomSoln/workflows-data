{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "738f6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "parent_dir = \"../../\"\n",
    "sys.path.append(parent_dir)\n",
    "os.chdir(parent_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26810498",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 250501 17:18:58 _constants:30] logger created, constants initialized\n",
      "/home/node/.local/share/virtualenvs/pipelines-ENKfgRKv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/node/.local/share/virtualenvs/pipelines-ENKfgRKv/lib/python3.9/site-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator LogisticRegression from version 1.4.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from workflows.workflow_text_classify import workflow_text_classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "690f5d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 250501 17:19:03 Workflow:192] Begin prepare_models\n",
      "[I 250501 17:19:03 prepare_models:37] positive keywords found: 4\n",
      "[I 250501 17:19:03 prepare_models:43] negative keywords found: 4\n",
      "[I 250501 17:19:03 prepare_models:54] finetune() using device: cpu\n",
      "[I 250501 17:19:03 prepare_models:74] no classification model data available, so no models trained\n",
      "[I 250501 17:19:03 prepare_models:37] positive keywords found: 1\n",
      "[I 250501 17:19:03 prepare_models:43] negative keywords found: 1\n",
      "[I 250501 17:19:03 prepare_models:54] finetune() using device: cpu\n",
      "[I 250501 17:19:03 prepare_models:74] no classification model data available, so no models trained\n",
      "[I 250501 17:19:03 Workflow:203] End prepare_models\n"
     ]
    }
   ],
   "source": [
    "check1 = workflow_text_classify.prepare_models()\n",
    "assert check1 == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "580a9e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 250501 17:19:08 Workflow:211] begin process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice indices must be integers or None or have an __index__ method\n",
      "slice indices must be integers or None or have an __index__ method\n",
      "slice indices must be integers or None or have an __index__ method\n",
      "slice indices must be integers or None or have an __index__ method\n",
      "INFO: Convert text to pdf took: 0.009002685546875 secsINFO: Convert stream to pdf took: 0.048923492431640625 secsINFO: Document `example-2` populated with 8 missing (None) attributes: ['id', 'reference_number', 'file_str', 'file_document', 'pp_toc', 'readability_score', 'tag_categories', 'summary']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 250501 17:19:08 TaskImport:48] exported processed file to: tests/test_wf_text_classify/tmp/1_PRESENTATION/example-2.pickle\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice indices must be integers or None or have an __index__ method\n",
      "slice indices must be integers or None or have an __index__ method\n",
      "slice indices must be integers or None or have an __index__ method\n",
      "slice indices must be integers or None or have an __index__ method\n",
      "INFO: Convert text to pdf took: 0.010015010833740234 secsINFO: Convert stream to pdf took: 0.04406929016113281 secsINFO: Document `example-1` populated with 8 missing (None) attributes: ['id', 'reference_number', 'file_str', 'file_document', 'pp_toc', 'readability_score', 'tag_categories', 'summary']"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 250501 17:19:08 TaskImport:48] exported processed file to: tests/test_wf_text_classify/tmp/1_PRESENTATION/example-1.pickle\n",
      "[I 250501 17:19:08 TaskImport:49] end ingest file location from /workspaces/spa-vdi-2/pipelines/tests/test_wf_text_classify/data with 2 files matching ['.txt', '.md', '.json']\n",
      "[I 250501 17:19:08 TaskTransform:41] end ingest file location from /workspaces/spa-vdi-2/pipelines/tests/test_wf_text_classify/tmp/1_PRESENTATION with 0 files matching []\n",
      "[I 250501 17:19:08 TaskTransform:94] completed text-classification processing for file 0\n",
      "[I 250501 17:19:08 Workflow:215] end process, execution took: 0.148sec\n"
     ]
    }
   ],
   "source": [
    "check2 = workflow_text_classify.run()\n",
    "assert check2 == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efcb370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipelines-ENKfgRKv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
